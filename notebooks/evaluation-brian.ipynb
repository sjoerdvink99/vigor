{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30bdf002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import networkx as nx\n",
    "# import os\n",
    "# from textwrap import dedent\n",
    "\n",
    "# import torch\n",
    "# from torch import nn\n",
    "# from torch import optim\n",
    "\n",
    "# from vigor.graph import Graph\n",
    "# from vigor import predicates\n",
    "\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# print(\"device\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56e2ae54",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f4fa306",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brian\\anaconda3\\envs\\vigor\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device cpu\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from vigor import predicates\n",
    "from vigor.evaluation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "783216f7",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# def extract_statistics(self) -> None:\n",
    "#         \"\"\"Extract statistics from the graph.\"\"\"\n",
    "#         # Topological Measures\n",
    "#         print('Topological')\n",
    "#         t = time()\n",
    "#         self.n_nodes = self.number_of_nodes()\n",
    "#         self.n_edges = self.number_of_edges()\n",
    "#         self.is_bipartite = 1 if nx.is_bipartite(self) else 0\n",
    "#         self.is_directed_int = int(self.is_directed())\n",
    "#         self.density = nx.density(self)\n",
    "#         self.n_components = nx.number_weakly_connected_components(self) if self.is_directed() else nx.number_connected_components(self)\n",
    "#         self.transitivity = nx.transitivity(self)\n",
    "#         print(time() - t)\n",
    "\n",
    "#         # If the graph is connected, calculate diameter, radius, and shortest path length\n",
    "#         print('Connected')\n",
    "#         t = time()\n",
    "#         if nx.is_connected(self):\n",
    "#             self.diameter = nx.diameter(self)\n",
    "#             self.avg_shortest_path_length = nx.average_shortest_path_length(self)\n",
    "#             ecc = nx.eccentricity(self)\n",
    "#             self.eccentricity_avg = sum(ecc.values()) / len(ecc) if ecc else 0.0\n",
    "#             self.radius = nx.radius(self)\n",
    "#         else:\n",
    "#             self.diameter = -1\n",
    "#             self.avg_shortest_path_length = -1\n",
    "#             self.eccentricity_avg = -1\n",
    "#             self.radius = -1\n",
    "#         print(time() - t)\n",
    "\n",
    "#         # Graph type\n",
    "#         print('Type')\n",
    "#         t = time()\n",
    "#         if nx.is_tree(self):\n",
    "#             self.graph_type = 1  # Tree\n",
    "#         elif self.n_nodes == self.n_edges and all(degree == 2 for _, degree in self.degree()):\n",
    "#             self.graph_type = 2  # Cycle\n",
    "#         else:\n",
    "#             self.graph_type = 3 if self.density <= 0.1 else 4\n",
    "#         print(time() - t)\n",
    "\n",
    "#         # Node Measures\n",
    "#         print('Node')\n",
    "#         t = time()\n",
    "#         node_types_set = {\",\".join(data['label']) if isinstance(data['label'], list) else data['label'] \n",
    "#                   for _, data in self.nodes(data=True) if 'label' in data}\n",
    "#         self.node_types = len(node_types_set)\n",
    "#         print(time() - t)\n",
    "\n",
    "#         # Calculate the average number of attributes per node\n",
    "#         print('Attributes')\n",
    "#         t = time()\n",
    "#         total_node_attributes = sum(len(data) for _, data in self.nodes(data=True))\n",
    "#         self.node_attributes = total_node_attributes / self.n_nodes if self.n_nodes > 0 else 0\n",
    "\n",
    "#         degrees = [degree for _, degree in self.degree()]\n",
    "#         self.avg_degree = sum(degrees) / self.n_nodes if self.n_nodes > 0 else 0\n",
    "#         self.std_degree = stdev(degrees) if len(degrees) > 1 else 0\n",
    "#         self.clustering_coefficient = nx.average_clustering(self)\n",
    "#         self.vertex_connectivity = nx.node_connectivity(self)\n",
    "# #         self.s_metric = nx.s_metric(self, False) if nx.is_connected(self) else -1\n",
    "# #         self.sigma = nx.sigma(self) if nx.is_connected(self) else -1\n",
    "# #         self.is_planar = 1 if nx.is_planar(self) else 0\n",
    "#         self.number_of_isolates = nx.number_of_isolates(self)\n",
    "#         print(time() - t)\n",
    "\n",
    "#         # Betweenness centrality\n",
    "#         print('Centrality')\n",
    "#         t = time()\n",
    "#         betweenness = nx.betweenness_centrality(self)\n",
    "#         self.avg_betweenness_centrality = sum(betweenness.values()) / len(betweenness) if betweenness else 0.0\n",
    "        \n",
    "#         closeness = nx.closeness_centrality(self)\n",
    "#         self.avg_closeness_centrality = sum(closeness.values()) / len(closeness) if closeness else 0.0\n",
    "\n",
    "#         eigenvector = nx.eigenvector_centrality(self)\n",
    "#         self.avg_eigenvector_centrality = sum(eigenvector.values()) / len(eigenvector) if eigenvector else 0.0\n",
    "#         print(time() - t)\n",
    "\n",
    "#         # Edge Measures\n",
    "#         print('Edges')\n",
    "#         t = time()\n",
    "#         edge_types_set = {data.get('type') for _, _, data in self.edges(data=True) if 'type' in data}\n",
    "#         self.edge_types = len(edge_types_set)\n",
    "        \n",
    "#         # Calculate the average number of attributes per edge\n",
    "#         total_edge_attributes = sum(len(data) for _, _, data in self.edges(data=True))\n",
    "#         self.edge_attributes = total_edge_attributes / self.n_edges if self.n_edges > 0 else 0\n",
    "\n",
    "#         self.n_self_loops = nx.number_of_selfloops(self)\n",
    "#         self.n_parallel_edges = sum(1 for u, v, k in self.edges(keys=True) if self.number_of_edges(u, v) > 1) if isinstance(self, (nx.MultiGraph, nx.MultiDiGraph)) else 0\n",
    "#         print(time() - t)\n",
    "        \n",
    "#         # Assortativity\n",
    "#         print('Assortativity')\n",
    "#         t = time()\n",
    "#         if self.n_edges > 0:\n",
    "#             try:\n",
    "#                 self.assortativity = float(nx.degree_assortativity_coefficient(self))\n",
    "#             except Exception as e:\n",
    "#                 print(f\"Error calculating assortativity: {e}\")\n",
    "#                 self.assortativity = float('nan')\n",
    "#         else:\n",
    "#             self.assortativity = float('nan')\n",
    "#         print(time() - t)\n",
    "\n",
    "#         # Check for spatial and temporal attributes using utility functions\n",
    "#         print('Spatial')\n",
    "#         t = time()\n",
    "#         self.has_spatial_attributes = int(any(\n",
    "#             is_spatial(key) for _, data in self.nodes(data=True) for key in data.keys()\n",
    "#         ) or any(\n",
    "#             is_spatial(key) for _, _, data in self.edges(data=True) for key in data.keys()\n",
    "#         ))\n",
    "\n",
    "#         self.has_temporal_attributes = int(any(\n",
    "#             is_temporal(key) for _, data in self.nodes(data=True) for key in data.keys()\n",
    "#         ) or any(\n",
    "#             is_temporal(key) for _, _, data in self.edges(data=True) for key in data.keys()\n",
    "#         ))\n",
    "#         print(time() - t)\n",
    "\n",
    "#         try:\n",
    "#             print('Modularity')\n",
    "#             t = time()\n",
    "#             self.modularity = self.calculate_modularity()\n",
    "#             print(time() - t)\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error calculating modularity: {e}\")\n",
    "#             self.modularity = float('nan')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f293fbb",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# def generate_graphs(num_graphs, nmin=2, nmax=200):\n",
    "#     all_graphs = []\n",
    "#     for i in range(num_graphs):\n",
    "#         n = np.random.randint(nmin, nmax)\n",
    "#         p = np.random.uniform(0, 1)\n",
    "#         print(n, p)\n",
    "#         G = nx.fast_gnp_random_graph(n, p)\n",
    "#         H = Graph()\n",
    "#         H.from_existing_graph(G)\n",
    "#         try:\n",
    "#             extract_statistics(H)\n",
    "#             all_graphs.append(H)\n",
    "#         except:\n",
    "#             print('FAILED')\n",
    "#         print()\n",
    "#     df = pd.DataFrame([{k: getattr(d, k) if hasattr(d, k) else np.NaN for k,v in d.__dataclass_fields__.items()} for d in all_graphs])\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "313ce4a5",
   "metadata": {
    "code_folding": [
     0,
     27,
     33,
     201
    ]
   },
   "outputs": [],
   "source": [
    "# def predict(x, a, mu):\n",
    "#     r\"\"\"\n",
    "#     UMAP-inspired predict function.\n",
    "#     A bump function centered at $\\\\mu$ with extent determined by $1/|a|$.\n",
    "\n",
    "#     $$ pred = \\frac{1}{1+ \\sum_{i=1}^{p} |a_i| * |x_i - \\mu_i|^{b}} $$\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     x - Torch tensor, shape [n_data_points, n_features]\n",
    "#         Input data points\n",
    "#     a - Torch tensor, shape [n_features]\n",
    "#         A parameter for the bounding box extent. 1/a.abs() is the extent of bounding box at prediction=0.5\n",
    "#     mu - Torch tensor, shape [n_features]\n",
    "#         A parameter for the bounding box center\n",
    "#     b - Scalar.\n",
    "#         Hyperparameter for predict function. Power exponent\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     pred - Torch tensor of predction for each point in x, shape = [n_data_points, 1]\n",
    "#     \"\"\"\n",
    "\n",
    "#     b = 4\n",
    "#     pred = 1 / (1 + ((a.abs() * (x - mu).abs()).pow(b)).sum(1))\n",
    "#     return pred\n",
    "\n",
    "# def compute_predicate_sequence(\n",
    "#     x0,\n",
    "#     selected,\n",
    "#     attribute_names=[],\n",
    "#     n_iter=1000,\n",
    "#     device=device,\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     x0 - numpy array, shape=[n_points, n_feature]. Data points\n",
    "#     selected - boolean array. shape=[brush_index, n_points] of selection\n",
    "#     \"\"\"\n",
    "\n",
    "#     n_points, n_features = x0.shape\n",
    "#     n_brushes = selected.shape[0]\n",
    "\n",
    "#     # prepare training data\n",
    "#     # orginal data extent\n",
    "#     vmin = x0.min(0)\n",
    "#     vmax = x0.max(0)\n",
    "#     x = torch.from_numpy(x0.astype(np.float32)).to(device)\n",
    "#     label = torch.from_numpy(selected).float().to(device)\n",
    "#     # normalize\n",
    "#     mean = x.mean(0)\n",
    "#     scale = x.std(0) + 1e-2\n",
    "#     x = (x - mean) / scale\n",
    "\n",
    "#     # Trainable parameters\n",
    "#     # since data is normalized,\n",
    "#     # mu can initialized around mean_pos examples\n",
    "#     # a can initialized around a constant across all axes\n",
    "#     selection_centroids = torch.stack([x[sel_t].mean(0) for sel_t in selected], 0)\n",
    "#     selection_std = torch.stack([x[sel_t].std(0) for sel_t in selected], 0)\n",
    "# #     print(selection_std)\n",
    "\n",
    "#     # initialize the bounding box center (mu) at the data centroid, +-0.1 at random\n",
    "#     mu_init = selection_centroids\n",
    "#     a_init = 1 / selection_std\n",
    "#     # a = (a_init + 0.1 * (2 * torch.rand(n_brushes, n_features) - 1)).to(device)\n",
    "#     # mu = mu_init + 0.1 * (2 * torch.rand(n_brushes, x.shape[1], device=device) - 1)\n",
    "#     a = a_init.to(device)\n",
    "#     mu = mu_init.to(device)\n",
    "#     a.requires_grad_(True)\n",
    "#     mu.requires_grad_(True)\n",
    "\n",
    "#     # For each brush,\n",
    "#     # weight-balance selected vs. unselected based on their size\n",
    "#     # and create a weighted BCE loss function (for each brush)\n",
    "#     bce_per_brush = []\n",
    "#     for st in selected:  # for each brush, define their class-balanced loss function\n",
    "#         n_selected = st.sum()  # st is numpy array\n",
    "#         n_unselected = n_points - n_selected\n",
    "#         instance_weight = torch.ones(x.shape[0]).to(device)\n",
    "#         instance_weight[st] = n_points / n_selected\n",
    "#         instance_weight[~st] = n_points / n_unselected\n",
    "#         bce = nn.BCELoss(weight=instance_weight)\n",
    "#         bce_per_brush.append(bce)\n",
    "\n",
    "#     optimizer = optim.SGD(\n",
    "#         [\n",
    "#             {\"params\": mu, \"weight_decay\": 0},\n",
    "#             # smaller a encourages larger range of the bounding box\n",
    "#             {\"params\": a, \"weight_decay\": 0.25},\n",
    "#         ],\n",
    "#         lr=1e-2,\n",
    "#         momentum=0.4,\n",
    "#         nesterov=True,\n",
    "#     )\n",
    "\n",
    "#     # training loop\n",
    "#     for e in range(n_iter):\n",
    "#         loss_per_brush = []\n",
    "#         for t, st in enumerate(selected):  # for each brush, compute loss\n",
    "#             # TODO try subsample:\n",
    "#             # use all selected data\n",
    "#             # randomly sample unselected data with similar size\n",
    "#             pred = predict(x, a[t], mu[t])\n",
    "# #             print(pred)\n",
    "#             loss = bce(pred, label[t])\n",
    "#             # loss += (mu[t] - selection_centroids[t]).pow(2).mean() * 20\n",
    "#             loss_per_brush.append(loss)\n",
    "#             smoothness_loss = 0\n",
    "#             if len(selected) == 2:\n",
    "#                 smoothness_loss += 5 * (a[1:] - a[:-1]).pow(2).mean()\n",
    "#                 smoothness_loss += 1 * (mu[1:] - mu[:-1]).pow(2).mean()\n",
    "#             elif len(selected) > 2:\n",
    "#                 smoothness_loss += 500 * (a[1:] - a[:-1]).pow(2).mean()\n",
    "#                 smoothness_loss += 10 * (mu[1:] - mu[:-1]).pow(2).mean()\n",
    "\n",
    "#         # print('bce', loss_per_brush)\n",
    "#         # print('smoothness', smoothness_loss.item())\n",
    "#         # sparsity_loss = 0\n",
    "#         # sparsity_loss = a.abs().mean() * 100\n",
    "#         total_loss = sum(loss_per_brush) + smoothness_loss  # + sparsity_loss\n",
    "#         optimizer.zero_grad()\n",
    "#         total_loss.backward()\n",
    "#         optimizer.step()\n",
    "#         if e % max(1, (n_iter // 10)) == 0:\n",
    "#             # print(pred.min().item(), pred.max().item())\n",
    "#             print(f\"[{e:>4}] loss {loss.item()}\")\n",
    "#     a.detach_()\n",
    "#     mu.detach_()\n",
    "#     # plt.stem(a.abs().numpy()); plt.show()\n",
    "\n",
    "#     qualities = []\n",
    "#     for t, st in enumerate(selected):  # for each brush, compute quality\n",
    "#         pred = predict(x, a[t], mu[t])\n",
    "#         pred = (pred > 0.5).float()\n",
    "#         correct = (pred == label[t]).float().sum().item()\n",
    "#         total = n_points\n",
    "#         accuracy = correct / total\n",
    "#         # 1 meaning points are selected\n",
    "#         tp = ((pred == 1).float() * (label == 1).float()).sum().item()\n",
    "#         fp = ((pred == 1).float() * (label == 0).float()).sum().item()\n",
    "#         fn = ((pred == 0).float() * (label == 1).float()).sum().item()\n",
    "#         precision = tp / (tp + fp) if tp + fp > 0 else 0\n",
    "#         recall = tp / (tp + fn) if tp + fn > 0 else 0\n",
    "#         f1 = 2 / (1 / precision + 1 / recall) if precision > 0 and recall > 0 else 0\n",
    "#         print(\n",
    "#             dedent(\n",
    "#                 f\"\"\"\n",
    "#             brush = {t}\n",
    "#             accuracy = {accuracy}\n",
    "#             precision = {precision}\n",
    "#             recall = {recall}\n",
    "#             f1 = {f1}\n",
    "#         \"\"\"\n",
    "#             )\n",
    "#         )\n",
    "#         qualities.append(\n",
    "#             dict(brush=t, accuracy=accuracy, precision=precision, recall=recall, f1=f1)\n",
    "#         )\n",
    "\n",
    "#     # predicate clause selection\n",
    "#     # r is the range of the bounding box on each dimension\n",
    "#     # bounding box is defined by the level set of prediction=0.5\n",
    "#     predicates = []\n",
    "#     # for each brush, generate a predicate from a[t] and mu[t]\n",
    "#     for t, st in enumerate(selected):\n",
    "#         r = 1 / a[t].abs()\n",
    "#         predicate_clauses = []\n",
    "#         for k in range(n_features):  # for each attribute\n",
    "#             vmin_selected = x0[st, k].min()\n",
    "#             vmax_selected = x0[st, k].max()\n",
    "#             # denormalize\n",
    "#             r_k = (r[k] * scale[k]).item()\n",
    "#             mu_k = (mu[t, k] * scale[k] + mean[k]).item()\n",
    "#             ci = [mu_k - r_k, mu_k + r_k]\n",
    "#             assert ci[0] < ci[1], \"ci[0] is not less than ci[1]\"\n",
    "#             if ci[0] < vmin[k]:\n",
    "#                 ci[0] = vmin[k]\n",
    "#             if ci[1] > vmax[k]:\n",
    "#                 ci[1] = vmax[k]\n",
    "\n",
    "#             # feature selection based on extent range\n",
    "#             #         should_include = r[k] < 1.0 * (x[:,k].max()-x[:,k].min())\n",
    "#             should_include = not (ci[0] <= vmin[k] and ci[1] >= vmax[k])\n",
    "\n",
    "#             if should_include:\n",
    "#                 if ci[0] < vmin_selected:\n",
    "#                     ci[0] = vmin_selected\n",
    "#                 if ci[1] > vmax_selected:\n",
    "#                     ci[1] = vmax_selected\n",
    "#                 predicate_clauses.append(\n",
    "#                     dict(\n",
    "#                         dim=k,\n",
    "#                         interval=ci,\n",
    "#                         attribute=attribute_names[k],\n",
    "#                     )\n",
    "#                 )\n",
    "#         predicates.append(predicate_clauses)\n",
    "#     parameters = dict(mu=mu, a=a)\n",
    "#     return predicates, qualities, parameters\n",
    "\n",
    "\n",
    "# class Predicate:\n",
    "    \n",
    "#     def __init__(self, clause_list=None, mask=None, mask_=None, clauses=None):\n",
    "#         self.clause_list = clause_list\n",
    "#         self.clauses = {clause['attribute']: clause['interval'] for clause in clause_list} if clauses is None else clauses\n",
    "#         self.mask_ = mask\n",
    "#         self.mask = mask_\n",
    "#         self.X = None\n",
    "#         self.attrs = tuple(set(self.clauses.keys()))\n",
    "        \n",
    "#     def __repr__(self):\n",
    "#         return str(self.clauses)\n",
    "        \n",
    "#     def fit(self, X):\n",
    "#         self.X = X\n",
    "#         self.mask_ = pd.DataFrame({k: (X[k]<v[1]) & (X[k]>v[0]) for k,v in self.clauses.items()})\n",
    "#         self.mask = self.mask_.all(axis=1)\n",
    "        \n",
    "#     def copy(self):\n",
    "#         predicate = Predicate(None, self.mask, self.mask_, self.clauses)\n",
    "#         if self.X is not None:\n",
    "#             predicate.fit(self.X)\n",
    "#         return predicate\n",
    "    \n",
    "#     def label(self, X, col, dim=None):\n",
    "#         if dim is not None:\n",
    "#             not_dim_mask = self.mask_.drop(dim, axis=1).all(axis=1)\n",
    "#             return self.mask_.loc[not_dim_mask,dim].astype(int)\n",
    "#         else:\n",
    "#             return self.mask.astype(int)        \n",
    "#     def update_clause(self, dim, a, b):\n",
    "#         clauses = {k:v for k,v in self.clauses.items()}\n",
    "#         clauses[dim] = [a, b]\n",
    "#         predicate = Predicate(None, clauses=clauses)\n",
    "#         if self.X is not None:\n",
    "#             predicate.fit(self.X)\n",
    "#         return predicate\n",
    "        \n",
    "#     def label_adjacent(self, X, col, dim):\n",
    "#         p1 = self.update_clause(dim, X[dim].min(), self.clauses[dim][0])\n",
    "#         p2 = self.update_clause(dim, self.clauses[dim][1], X[dim].max())\n",
    "#         return p1, p2, p1.label(X, col, dim), p2.label(X, col, dim)\n",
    "\n",
    "# def get_predicates(X, y, n_iter=1000):\n",
    "#     predicates, qualities, parameters = compute_predicate_sequence(\n",
    "#         X.values,\n",
    "#         y[None],\n",
    "#         attribute_names=X.columns,\n",
    "#         n_iter=n_iter,\n",
    "#     )\n",
    "    \n",
    "#     p = Predicate(predicates[0])\n",
    "#     p.fit(X)\n",
    "#     return p\n",
    "    \n",
    "#     sent_norm = (sentences.drop(['id', 'sentence'], axis=1) - X.min()) / (X.max() - X.min())\n",
    "#     sentence_p = doc_p.copy()\n",
    "#     sentence_p.fit(sent_norm)\n",
    "#     return doc_p, sentence_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a276c3a",
   "metadata": {
    "code_folding": [
     0,
     12,
     15
    ]
   },
   "outputs": [],
   "source": [
    "# def fit_predicates(df, predicates):\n",
    "#     vistype_predicates = {}\n",
    "#     for vistype, attr, minval, maxval in predicates:\n",
    "#         if attr in df.columns:\n",
    "#             predicate = Predicate(clauses={attr: [minval, maxval]})\n",
    "#             predicate.fit(df)\n",
    "#             if vistype.name in vistype_predicates:\n",
    "#                 vistype_predicates[vistype.name].append(predicate)\n",
    "#             else:\n",
    "#                 vistype_predicates[vistype.name] = [predicate]\n",
    "#     return vistype_predicates\n",
    "\n",
    "# def get_vistype_labels(predicates):\n",
    "#     return pd.DataFrame({p.attrs[0]: p.mask for p in predicates})\n",
    "\n",
    "# def get_labels(vistype_predicates):\n",
    "#     vistype_labels = {k: get_vistype_labels(v) for k,v in vistype_predicates.items()}\n",
    "#     scores = pd.DataFrame({k: v.sum(axis=1) for k,v in vistype_labels.items()})\n",
    "#     labels = scores.idxmax(axis=1)\n",
    "#     return labels, scores, vistype_labels\n",
    "\n",
    "# def get_predicate_labels(df, predicates):\n",
    "#     vistype_predicates = fit_predicates(df, predicates)\n",
    "#     labels, scores, vistype_labels = get_labels(vistype_predicates)\n",
    "#     return {'predicates': vistype_predicates, 'labels': labels}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bf1944",
   "metadata": {},
   "source": [
    "# Generate Graphs and Statistics\n",
    "\n",
    "1. Generate graphs using the fast_gnp_random_graph function from networkx\n",
    "\n",
    "2. Calculate statistics for each graph\n",
    "\n",
    "    * s_metric, sigma, and is_planar are prohibitively expensive to compute for a large number of graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c98175a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading graph data\n"
     ]
    }
   ],
   "source": [
    "file_path = 'graph_data'\n",
    "if not os.path.exists(f'{file_path}.csv'):\n",
    "    print('generating graph data')\n",
    "    df = generate_graphs(300, 2, 200)\n",
    "else:\n",
    "    print('loading graph data')\n",
    "    df = pd.read_csv(f'{file_path}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "510d8671",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>graph_type</th>\n",
       "      <th>is_directed_int</th>\n",
       "      <th>has_spatial_attributes</th>\n",
       "      <th>has_temporal_attributes</th>\n",
       "      <th>is_planar</th>\n",
       "      <th>is_bipartite</th>\n",
       "      <th>n_components</th>\n",
       "      <th>avg_betweenness_centrality</th>\n",
       "      <th>avg_closeness_centrality</th>\n",
       "      <th>avg_eigenvector_centrality</th>\n",
       "      <th>...</th>\n",
       "      <th>sigma</th>\n",
       "      <th>n_nodes</th>\n",
       "      <th>node_types</th>\n",
       "      <th>node_attributes</th>\n",
       "      <th>number_of_isolates</th>\n",
       "      <th>density</th>\n",
       "      <th>edge_types</th>\n",
       "      <th>edge_attributes</th>\n",
       "      <th>n_parallel_edges</th>\n",
       "      <th>n_self_loops</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>0.947804</td>\n",
       "      <td>0.097103</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.944474</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.004174</td>\n",
       "      <td>0.583721</td>\n",
       "      <td>0.075489</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>173</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.286194</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.004833</td>\n",
       "      <td>0.641326</td>\n",
       "      <td>0.091558</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.439374</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.102564</td>\n",
       "      <td>0.376141</td>\n",
       "      <td>0.240887</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.179487</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000759</td>\n",
       "      <td>0.947525</td>\n",
       "      <td>0.114659</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.943860</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001242</td>\n",
       "      <td>0.856071</td>\n",
       "      <td>0.085069</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.831059</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.050950</td>\n",
       "      <td>0.140664</td>\n",
       "      <td>0.065252</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.029343</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.004470</td>\n",
       "      <td>0.575750</td>\n",
       "      <td>0.076719</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>167</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.262463</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001171</td>\n",
       "      <td>0.815435</td>\n",
       "      <td>0.071373</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>196</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.772894</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>0.985032</td>\n",
       "      <td>0.123080</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.984615</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>297 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     graph_type  is_directed_int  has_spatial_attributes  \\\n",
       "0             4                0                       0   \n",
       "1             4                0                       0   \n",
       "2             4                0                       0   \n",
       "3             4                0                       0   \n",
       "4             4                0                       0   \n",
       "..          ...              ...                     ...   \n",
       "292           4                0                       0   \n",
       "293           3                0                       0   \n",
       "294           4                0                       0   \n",
       "295           4                0                       0   \n",
       "296           4                0                       0   \n",
       "\n",
       "     has_temporal_attributes  is_planar  is_bipartite  n_components  \\\n",
       "0                          0        NaN             0             1   \n",
       "1                          0        NaN             0             1   \n",
       "2                          0        NaN             0             1   \n",
       "3                          0        NaN             0             2   \n",
       "4                          0        NaN             0             1   \n",
       "..                       ...        ...           ...           ...   \n",
       "292                        0        NaN             0             1   \n",
       "293                        0        NaN             0             8   \n",
       "294                        0        NaN             0             1   \n",
       "295                        0        NaN             0             1   \n",
       "296                        0        NaN             0             1   \n",
       "\n",
       "     avg_betweenness_centrality  avg_closeness_centrality  \\\n",
       "0                      0.000534                  0.947804   \n",
       "1                      0.004174                  0.583721   \n",
       "2                      0.004833                  0.641326   \n",
       "3                      0.102564                  0.376141   \n",
       "4                      0.000759                  0.947525   \n",
       "..                          ...                       ...   \n",
       "292                    0.001242                  0.856071   \n",
       "293                    0.050950                  0.140664   \n",
       "294                    0.004470                  0.575750   \n",
       "295                    0.001171                  0.815435   \n",
       "296                    0.000240                  0.985032   \n",
       "\n",
       "     avg_eigenvector_centrality  ...  sigma  n_nodes  node_types  \\\n",
       "0                      0.097103  ...    NaN      106           0   \n",
       "1                      0.075489  ...    NaN      173           0   \n",
       "2                      0.091558  ...    NaN      118           0   \n",
       "3                      0.240887  ...    NaN       13           0   \n",
       "4                      0.114659  ...    NaN       76           0   \n",
       "..                          ...  ...    ...      ...         ...   \n",
       "292                    0.085069  ...    NaN      138           0   \n",
       "293                    0.065252  ...    NaN       72           0   \n",
       "294                    0.076719  ...    NaN      167           0   \n",
       "295                    0.071373  ...    NaN      196           0   \n",
       "296                    0.123080  ...    NaN       66           0   \n",
       "\n",
       "     node_attributes  number_of_isolates   density  edge_types  \\\n",
       "0                0.0                   0  0.944474           0   \n",
       "1                0.0                   0  0.286194           0   \n",
       "2                0.0                   0  0.439374           0   \n",
       "3                0.0                   1  0.179487           0   \n",
       "4                0.0                   0  0.943860           0   \n",
       "..               ...                 ...       ...         ...   \n",
       "292              0.0                   0  0.831059           0   \n",
       "293              0.0                   6  0.029343           0   \n",
       "294              0.0                   0  0.262463           0   \n",
       "295              0.0                   0  0.772894           0   \n",
       "296              0.0                   0  0.984615           0   \n",
       "\n",
       "     edge_attributes  n_parallel_edges  n_self_loops  \n",
       "0                0.0                 0             0  \n",
       "1                0.0                 0             0  \n",
       "2                0.0                 0             0  \n",
       "3                0.0                 0             0  \n",
       "4                0.0                 0             0  \n",
       "..               ...               ...           ...  \n",
       "292              0.0                 0             0  \n",
       "293              0.0                 0             0  \n",
       "294              0.0                 0             0  \n",
       "295              0.0                 0             0  \n",
       "296              0.0                 0             0  \n",
       "\n",
       "[297 rows x 33 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1ca3ab",
   "metadata": {},
   "source": [
    "# Prepare Data for Predicate Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "643922fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_std = df.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71fb1bb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "graph_type                     0.396574\n",
       "is_directed_int                0.000000\n",
       "has_spatial_attributes         0.000000\n",
       "has_temporal_attributes        0.000000\n",
       "is_planar                           NaN\n",
       "is_bipartite                   0.189171\n",
       "n_components                   1.400327\n",
       "avg_betweenness_centrality     0.029138\n",
       "avg_closeness_centrality       0.190156\n",
       "avg_eigenvector_centrality     0.091201\n",
       "avg_degree                    40.999756\n",
       "std_degree                     1.722291\n",
       "clustering_coefficient         0.295832\n",
       "transitivity                   0.295636\n",
       "modularity                     0.104869\n",
       "communities                    1.401977\n",
       "avg_shortest_path_length       0.699630\n",
       "radius                         0.856768\n",
       "diameter                       1.055290\n",
       "assortativity                  0.112348\n",
       "vertex_connectivity           38.332860\n",
       "eccentricity_avg               0.922103\n",
       "s_metric                            NaN\n",
       "sigma                               NaN\n",
       "n_nodes                       56.939827\n",
       "node_types                     0.000000\n",
       "node_attributes                0.000000\n",
       "number_of_isolates             0.954262\n",
       "density                        0.287013\n",
       "edge_types                     0.000000\n",
       "edge_attributes                0.000000\n",
       "n_parallel_edges               0.000000\n",
       "n_self_loops                   0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attr_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70538ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_null = df.isnull().any(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c47fdc43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "graph_type                    False\n",
       "is_directed_int               False\n",
       "has_spatial_attributes        False\n",
       "has_temporal_attributes       False\n",
       "is_planar                      True\n",
       "is_bipartite                  False\n",
       "n_components                  False\n",
       "avg_betweenness_centrality    False\n",
       "avg_closeness_centrality      False\n",
       "avg_eigenvector_centrality    False\n",
       "avg_degree                    False\n",
       "std_degree                    False\n",
       "clustering_coefficient        False\n",
       "transitivity                  False\n",
       "modularity                    False\n",
       "communities                    True\n",
       "avg_shortest_path_length      False\n",
       "radius                        False\n",
       "diameter                      False\n",
       "assortativity                  True\n",
       "vertex_connectivity           False\n",
       "eccentricity_avg              False\n",
       "s_metric                       True\n",
       "sigma                          True\n",
       "n_nodes                       False\n",
       "node_types                    False\n",
       "node_attributes               False\n",
       "number_of_isolates            False\n",
       "density                       False\n",
       "edge_types                    False\n",
       "edge_attributes               False\n",
       "n_parallel_edges              False\n",
       "n_self_loops                  False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attr_null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4197f17",
   "metadata": {},
   "source": [
    "**Only use attributes that do not contain null values and have a standard deviation > 0:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "affa0aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_use = (attr_std.fillna(0)>0) & ~attr_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a4d364b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "graph_type                     True\n",
       "is_directed_int               False\n",
       "has_spatial_attributes        False\n",
       "has_temporal_attributes       False\n",
       "is_planar                     False\n",
       "is_bipartite                   True\n",
       "n_components                   True\n",
       "avg_betweenness_centrality     True\n",
       "avg_closeness_centrality       True\n",
       "avg_eigenvector_centrality     True\n",
       "avg_degree                     True\n",
       "std_degree                     True\n",
       "clustering_coefficient         True\n",
       "transitivity                   True\n",
       "modularity                     True\n",
       "communities                   False\n",
       "avg_shortest_path_length       True\n",
       "radius                         True\n",
       "diameter                       True\n",
       "assortativity                 False\n",
       "vertex_connectivity            True\n",
       "eccentricity_avg               True\n",
       "s_metric                      False\n",
       "sigma                         False\n",
       "n_nodes                        True\n",
       "node_types                    False\n",
       "node_attributes               False\n",
       "number_of_isolates             True\n",
       "density                        True\n",
       "edge_types                    False\n",
       "edge_attributes               False\n",
       "n_parallel_edges              False\n",
       "n_self_loops                  False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attr_use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92639655",
   "metadata": {},
   "source": [
    "**Excluded Attributes:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85373af0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['is_directed_int', 'has_spatial_attributes', 'has_temporal_attributes',\n",
       "       'is_planar', 'communities', 'assortativity', 's_metric', 'sigma',\n",
       "       'node_types', 'node_attributes', 'edge_types', 'edge_attributes',\n",
       "       'n_parallel_edges', 'n_self_loops'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attr_use[~attr_use].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b59f336",
   "metadata": {},
   "outputs": [],
   "source": [
    "attr = attr_use[attr_use].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c0f4595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['graph_type', 'is_bipartite', 'n_components',\n",
       "       'avg_betweenness_centrality', 'avg_closeness_centrality',\n",
       "       'avg_eigenvector_centrality', 'avg_degree', 'std_degree',\n",
       "       'clustering_coefficient', 'transitivity', 'modularity',\n",
       "       'avg_shortest_path_length', 'radius', 'diameter', 'vertex_connectivity',\n",
       "       'eccentricity_avg', 'n_nodes', 'number_of_isolates', 'density'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "110cfad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(attr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef4848a",
   "metadata": {},
   "source": [
    "# Load Expert Predicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b1246711",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicates_labels = get_predicate_labels(df, predicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6f85e0",
   "metadata": {},
   "source": [
    "**List of predicates for each vis type:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1121e0af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NODELINK': [{'density': [0, 0.1]},\n",
       "  {'avg_degree': [1, 3]},\n",
       "  {'clustering_coefficient': [0.1, 0.4]},\n",
       "  {'node_types': [1, 3]},\n",
       "  {'edge_types': [1, 2]}],\n",
       " 'MATRIX': [{'density': [0.1, 1]},\n",
       "  {'avg_degree': [10, 50]},\n",
       "  {'modularity': [0.3, 0.7]},\n",
       "  {'node_attributes': [2, 10]},\n",
       "  {'edge_attributes': [1, 5]}],\n",
       " 'NODETRIX': [{'communities': [4, 10]},\n",
       "  {'clustering_coefficient': [0.5, 1]},\n",
       "  {'density': [0.1, 0.5]},\n",
       "  {'node_types': [2, 5]},\n",
       "  {'modularity': [0.3, 0.8]},\n",
       "  {'avg_degree': [5, 15]},\n",
       "  {'node_attributes': [3, 10]},\n",
       "  {'edge_types': [1, 3]}],\n",
       " 'NODELINK_MAP': [{'avg_degree': [1, 5]}],\n",
       " 'PAOHVIS': [{'n_nodes': [50, 500]},\n",
       "  {'node_types': [3, 6]},\n",
       "  {'edge_types': [2, 5]},\n",
       "  {'density': [0.05, 0.2]},\n",
       "  {'avg_degree': [5, 10]},\n",
       "  {'transitivity': [0.2, 0.6]}],\n",
       " 'CHORD_DIAGRAM': [{'n_nodes': [0, 6]},\n",
       "  {'edge_types': [1, 3]},\n",
       "  {'clustering_coefficient': [0.3, 0.7]},\n",
       "  {'avg_degree': [2, 4]}],\n",
       " 'TREEMAP': [{'graph_type': [0.5, 1.5]},\n",
       "  {'modularity': [0.5, 1]},\n",
       "  {'n_nodes': [50, 200]},\n",
       "  {'node_attributes': [5, 20]},\n",
       "  {'edge_attributes': [0, 2]}]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicates_labels['predicates']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b355f681",
   "metadata": {},
   "source": [
    "**Vis type label for each graph:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b8ab7cbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        MATRIX\n",
       "1        MATRIX\n",
       "2       PAOHVIS\n",
       "3      NODELINK\n",
       "4        MATRIX\n",
       "         ...   \n",
       "292      MATRIX\n",
       "293    NODELINK\n",
       "294      MATRIX\n",
       "295      MATRIX\n",
       "296      MATRIX\n",
       "Length: 297, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicates_labels['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e495de0",
   "metadata": {},
   "source": [
    "For each graph, each vis type gets one point for a matching predicate. The vis type with the most total points/matching predicates is chosen as the label."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca09b62d",
   "metadata": {},
   "source": [
    "# Learn Predicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cd67c3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_predicates_label(X_norm, label, labels, n_iter=1000):\n",
    "#     ypos = (labels == label).values\n",
    "#     yneg = ~ypos\n",
    "#     pred_pos = get_predicates(X_norm, ypos, n_iter=n_iter)\n",
    "#     pred_neg = get_predicates(X_norm, yneg, n_iter=n_iter)\n",
    "#     return pred_pos, pred_neg\n",
    "\n",
    "# def get_predicates_labels(df, attrs, labels, label_names=None, n_iter=1000):\n",
    "#     X = df[attrs]\n",
    "#     X_norm = (X - X.min()) / (X.max() - X.min())\n",
    "#     label_names = labels.unique() if label_names is None else label_names\n",
    "#     return {label: get_predicates_label(X_norm, label, labels, n_iter=n_iter) for label in label_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fdfaf10a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0] loss 3.3214240074157715\n",
      "[ 100] loss 9.225895881652832\n",
      "[ 200] loss 9.427505493164062\n",
      "[ 300] loss 0.22784195840358734\n",
      "[ 400] loss 0.1697160005569458\n",
      "[ 500] loss 0.19681721925735474\n",
      "[ 600] loss 0.24632522463798523\n",
      "[ 700] loss 0.3140135109424591\n",
      "[ 800] loss 0.3935486078262329\n",
      "[ 900] loss 0.47320684790611267\n",
      "\n",
      "brush = 0\n",
      "accuracy = 0.7811447811447811\n",
      "precision = 0.2261904761904762\n",
      "recall = 1.0\n",
      "f1 = 0.3689320388349515\n",
      "\n",
      "[   0] loss 2.5393917560577393\n",
      "[ 100] loss 0.6756349205970764\n",
      "[ 200] loss 0.2764913737773895\n",
      "[ 300] loss 0.21806229650974274\n",
      "[ 400] loss 0.19411863386631012\n",
      "[ 500] loss 0.18646377325057983\n",
      "[ 600] loss 0.19039420783519745\n",
      "[ 700] loss 0.19553092122077942\n",
      "[ 800] loss 0.199416846036911\n",
      "[ 900] loss 0.20200425386428833\n",
      "\n",
      "brush = 0\n",
      "accuracy = 0.9663299663299664\n",
      "precision = 1.0\n",
      "recall = 0.9640287769784173\n",
      "f1 = 0.9816849816849818\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learned_predicates = get_predicates_labels(df, attr, predicates_labels['labels'], label_names=['NODELINK'], n_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "67532967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NODELINK\n",
      "({'avg_degree': [0.003195298575763901, 0.02762993474337021], 'vertex_connectivity': [0.0, 0.011834319526627219]}, {'n_components': [0.0, 0.10526315789473684], 'avg_betweenness_centrality': [0.0, 0.15302101895213127], 'eccentricity_avg': [0.23305794596672058, 0.7996454536914825], 'number_of_isolates': [0.0, 0.18181818181818182]})\n"
     ]
    }
   ],
   "source": [
    "for vistype, predicate in learned_predicates.items():\n",
    "    print(vistype)\n",
    "    print(predicate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
